#  Desafio T√©cnico ‚Äì Infomaz 

An√°lise de dados para o estudo de caso proposto pela Infomaz, com foco em pipeline de ingest√£o, transforma√ß√£o e visualiza√ß√£o usando Python, Meltano, Docker e Jupyter.

## Tecnologias

- Python (Version **3.13.1**)
- Meltano (Version **3.6.0**)
- Docker (Version **27.3.1**)
- Jupyter Client (Version **8.6.3**)
- PostgresSQL (Version **14.15.0**)

## Instala√ß√£o

1. Clone o reposit√≥rio

```bash
git clone git@github.com:douglasmnegri/infomaz-case.git
cd infomaz-case
```

2. Python Environment (Recomendado)

```bash
python3 -m venv venv_nome
source venv_nome/bin/activate  # macOS/Linux
```

3. Instale as depend√™ncias atrav√©s do requirements.txt 

```bash
pip install -r requirements.txt
```

4. Configura√ß√£o do Meltano

```bash
  meltano install
```

## Inicializando o Projeto

1. Partindo do diret√≥rio ra√≠z (infomaz-case) execute docker-compose.yml que cont√©m base de dados do projeto:

```bash
docker-compose up -d
```

2. Execute o pipeline de ingest√£o de dados (ELT):

```bash
meltano run load-all-csv
```

3. Converta os valores num√©ricos para o formato correto com o script de transforma√ß√£o:
   
```bash
   python3 transform/clean_values.py
```

4. Inicialize o Jupyter Notebook

```bash
jupyter notebook notebook/infomaz_analysis.ipynb
```

5. Acesse o dashboard no navegador:
- üîó http://localhost:8888/notebooks/infomaz_analysis.ipynb

## Considera√ß√µes

Para este desafio, optei por estruturar uma pipeline de dados que permitisse organizar e carregar as informa√ß√µes do estudo de caso em um banco de dados relacional. Essa abordagem busca simular um ambiente real de projetos em produ√ß√£o, onde os dados de entrada, muitas vezes em planilhas, podem passar por altera√ß√µes ou atualiza√ß√µes ao longo do tempo.

Com essa estrutura, qualquer modifica√ß√£o nos dados de origem pode ser facilmente refletida nas an√°lises finais por meio da simples execu√ß√£o do pipeline ETL. Isso proporciona maior flexibilidade e escalabilidade para o processo de an√°lise!